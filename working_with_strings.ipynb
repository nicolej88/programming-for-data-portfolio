{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdT0fwTCa4gI"
   },
   "source": [
    "# Working with Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozWLM6Pfa7d_"
   },
   "source": [
    "### Exercise 1 strings\n",
    "---\n",
    "The pandas library has a similar set of string functions to those available in python generally.  Because we often want to perform operations on a whole series of data values in a dataframe, we can use pandas string functions to do this:\n",
    "\n",
    "Let's use the data set 'Housing in London' at 'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\n",
    "\n",
    "Read the dataset into a pandas dataframe and inspect the data.  The date, in this dataset is a string.   If we want to filter for a particular year, we will need to extract the first four letters as a substring.  We can create a new column called **year**, which just contains the year, stored as a number.\n",
    "\n",
    "The date is written in the format yyyy-mm-dd.  We can split the year around the '-' and then use the first component, converting it to an integer\n",
    "\n",
    "Reference:  \n",
    "\n",
    "Series.str.split() *to split a column's strings into components*    \n",
    "Series.str.get() *to get one of the components after the split*  \n",
    "\n",
    "You can **daisychain** these together:   \n",
    "\n",
    "`Series.str.split().str.get()`\n",
    "\n",
    "Have a go\n",
    "\n",
    "**Test output**:  \n",
    "\n",
    "```\n",
    "0       1999\n",
    "1       1999\n",
    "2       1999\n",
    "3       1999\n",
    "4       1999\n",
    "        ... \n",
    "1066    2019\n",
    "1067    2019\n",
    "1068    2019\n",
    "1069    2019\n",
    "1070    2019\n",
    "Name: year, Length: 1071, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "ZuLewd421t_c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1999\n",
       "1       1999\n",
       "2       1999\n",
       "3       1999\n",
       "4       1999\n",
       "        ... \n",
       "1066    2019\n",
       "1067    2019\n",
       "1068    2019\n",
       "1069    2019\n",
       "1070    2019\n",
       "Name: year, Length: 1071, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv'\n",
    "\n",
    "housing_london = pd.read_csv(url)\n",
    "\n",
    "housing_london[\"year\"]= housing_london[\"date\"].str.split(\"-\").str.get(0)\n",
    "\n",
    "display(housing_london[\"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPAgjR5U1utf"
   },
   "source": [
    "### Exercise 2\n",
    "---\n",
    "\n",
    "In exercise 1 you have extracted the year, but it's dtype is 'object' (it is still a string).  You can convert to integer by adding  .astype(int) to the daisychain.\n",
    "\n",
    "**Test output**:  \n",
    "\n",
    "```\n",
    "...\n",
    "Name: year, Length: 1071, dtype: int64\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "3SuKrrvD2f1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1999\n",
       "1       1999\n",
       "2       1999\n",
       "3       1999\n",
       "4       1999\n",
       "        ... \n",
       "1066    2019\n",
       "1067    2019\n",
       "1068    2019\n",
       "1069    2019\n",
       "1070    2019\n",
       "Name: year, Length: 1071, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>city of london</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>33020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48922</td>\n",
       "      <td>0</td>\n",
       "      <td>6581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23620</td>\n",
       "      <td>3</td>\n",
       "      <td>162444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23128</td>\n",
       "      <td>8</td>\n",
       "      <td>313469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>bexley</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21386</td>\n",
       "      <td>18</td>\n",
       "      <td>217458.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E09000005</td>\n",
       "      <td>brent</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18532.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20911</td>\n",
       "      <td>6</td>\n",
       "      <td>260317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code                  area        date  median_salary  \\\n",
       "0  E09000001        city of london  1999-12-01        33020.0   \n",
       "1  E09000002  barking and dagenham  1999-12-01        21480.0   \n",
       "2  E09000003                barnet  1999-12-01        19568.0   \n",
       "3  E09000004                bexley  1999-12-01        18621.0   \n",
       "4  E09000005                 brent  1999-12-01        18532.0   \n",
       "\n",
       "   life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "0                NaN       48922             0           6581.0   \n",
       "1                NaN       23620             3         162444.0   \n",
       "2                NaN       23128             8         313469.0   \n",
       "3                NaN       21386            18         217458.0   \n",
       "4                NaN       20911             6         260317.0   \n",
       "\n",
       "   number_of_jobs  area_size  no_of_houses  borough_flag  year  \n",
       "0             NaN        NaN           NaN             1  1999  \n",
       "1             NaN        NaN           NaN             1  1999  \n",
       "2             NaN        NaN           NaN             1  1999  \n",
       "3             NaN        NaN           NaN             1  1999  \n",
       "4             NaN        NaN           NaN             1  1999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "housing_london[\"year\"]= housing_london[\"date\"].str.split(\"-\").str.get(0).astype(int)\n",
    "display (housing_london['year'])\n",
    "display (housing_london.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spoUBwxT2gSi"
   },
   "source": [
    "### Exercise 3\n",
    "---\n",
    "\n",
    "All the areas in the data set are in lower case.  To prepare the data for reporting, you may want to capitalise.  Use .str.title() to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "5fLUjUYk4AyI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>City Of London</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>33020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48922</td>\n",
       "      <td>0</td>\n",
       "      <td>6581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>Barking And Dagenham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23620</td>\n",
       "      <td>3</td>\n",
       "      <td>162444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>Barnet</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23128</td>\n",
       "      <td>8</td>\n",
       "      <td>313469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>Bexley</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21386</td>\n",
       "      <td>18</td>\n",
       "      <td>217458.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E09000005</td>\n",
       "      <td>Brent</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18532.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20911</td>\n",
       "      <td>6</td>\n",
       "      <td>260317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code                  area        date  median_salary  \\\n",
       "0  E09000001        City Of London  1999-12-01        33020.0   \n",
       "1  E09000002  Barking And Dagenham  1999-12-01        21480.0   \n",
       "2  E09000003                Barnet  1999-12-01        19568.0   \n",
       "3  E09000004                Bexley  1999-12-01        18621.0   \n",
       "4  E09000005                 Brent  1999-12-01        18532.0   \n",
       "\n",
       "   life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "0                NaN       48922             0           6581.0   \n",
       "1                NaN       23620             3         162444.0   \n",
       "2                NaN       23128             8         313469.0   \n",
       "3                NaN       21386            18         217458.0   \n",
       "4                NaN       20911             6         260317.0   \n",
       "\n",
       "   number_of_jobs  area_size  no_of_houses  borough_flag  year  \n",
       "0             NaN        NaN           NaN             1  1999  \n",
       "1             NaN        NaN           NaN             1  1999  \n",
       "2             NaN        NaN           NaN             1  1999  \n",
       "3             NaN        NaN           NaN             1  1999  \n",
       "4             NaN        NaN           NaN             1  1999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "housing_london['area']= housing_london['area'].str.title()\n",
    "display (housing_london.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuUQQF2a4CPX"
   },
   "source": [
    "### Exercise 4 - Filter all areas to find all with 'and' in the name\n",
    "---\n",
    "\n",
    "Use str.contains() and a search (e.g. df[df['area'].str.contains()) to filter for all areas with 'and' in the name\n",
    "\n",
    "**Test output**:  \n",
    "105 rows × 13 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "pmT32YMq4BA8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23620</td>\n",
       "      <td>3</td>\n",
       "      <td>162444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>hammersmith and fulham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28555</td>\n",
       "      <td>7</td>\n",
       "      <td>160634.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E09000020</td>\n",
       "      <td>kensington and chelsea</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>20646.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28074</td>\n",
       "      <td>13</td>\n",
       "      <td>147678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>E12000003</td>\n",
       "      <td>yorkshire and the humber</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16527.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18977</td>\n",
       "      <td>7</td>\n",
       "      <td>4956325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>K04000001</td>\n",
       "      <td>england and wales</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51933471.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>28738.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>hammersmith and fulham</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>37990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>E09000020</td>\n",
       "      <td>kensington and chelsea</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>E12000003</td>\n",
       "      <td>yorkshire and the humber</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>27835.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>K04000001</td>\n",
       "      <td>england and wales</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>30500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           code                      area        date  median_salary  \\\n",
       "1     E09000002      barking and dagenham  1999-12-01        21480.0   \n",
       "12    E09000013    hammersmith and fulham  1999-12-01        25000.0   \n",
       "19    E09000020    kensington and chelsea  1999-12-01        20646.0   \n",
       "35    E12000003  yorkshire and the humber  1999-12-01        16527.0   \n",
       "47    K04000001         england and wales  1999-12-01        17974.0   \n",
       "...         ...                       ...         ...            ...   \n",
       "1021  E09000002      barking and dagenham  2019-12-01        28738.0   \n",
       "1032  E09000013    hammersmith and fulham  2019-12-01        37990.0   \n",
       "1039  E09000020    kensington and chelsea  2019-12-01        33000.0   \n",
       "1055  E12000003  yorkshire and the humber  2019-12-01        27835.0   \n",
       "1067  K04000001         england and wales  2019-12-01        30500.0   \n",
       "\n",
       "      life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "1                   NaN       23620             3         162444.0   \n",
       "12                  NaN       28555             7         160634.0   \n",
       "19                  NaN       28074            13         147678.0   \n",
       "35                  NaN       18977             7        4956325.0   \n",
       "47                  NaN       21549           NaN       51933471.0   \n",
       "...                 ...         ...           ...              ...   \n",
       "1021                NaN       32010           NaN              NaN   \n",
       "1032                NaN       48362           NaN              NaN   \n",
       "1039                NaN       41741           NaN              NaN   \n",
       "1055                NaN       32653           NaN              NaN   \n",
       "1067                NaN       37865           NaN              NaN   \n",
       "\n",
       "      number_of_jobs  area_size  no_of_houses  borough_flag  year  \n",
       "1                NaN        NaN           NaN             1  1999  \n",
       "12               NaN        NaN           NaN             1  1999  \n",
       "19               NaN        NaN           NaN             1  1999  \n",
       "35               NaN        NaN           NaN             0  1999  \n",
       "47               NaN        NaN           NaN             0  1999  \n",
       "...              ...        ...           ...           ...   ...  \n",
       "1021             NaN        NaN           NaN             1  2019  \n",
       "1032             NaN        NaN           NaN             1  2019  \n",
       "1039             NaN        NaN           NaN             1  2019  \n",
       "1055             NaN        NaN           NaN             0  2019  \n",
       "1067             NaN        NaN           NaN             0  2019  \n",
       "\n",
       "[105 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_and = housing_london[housing_london['area'].str.contains(' and ')]\n",
    "display (filter_and)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ChmyffT7wDK"
   },
   "source": [
    "### Exercise 4\n",
    "---\n",
    "\n",
    "Filter the data for all areas starting with 'ba'  \n",
    "\n",
    "Test output:  \n",
    "21 rows, all city of london"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "li8sAN3O8Zxp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23620</td>\n",
       "      <td>3</td>\n",
       "      <td>162444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23128</td>\n",
       "      <td>8</td>\n",
       "      <td>313469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>22618.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24696</td>\n",
       "      <td>4</td>\n",
       "      <td>163893.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>21761.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25755</td>\n",
       "      <td>8</td>\n",
       "      <td>315784.0</td>\n",
       "      <td>138000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2001-12-01</td>\n",
       "      <td>22323.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26050</td>\n",
       "      <td>3</td>\n",
       "      <td>165654.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>68298.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2001-12-01</td>\n",
       "      <td>20916.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26068</td>\n",
       "      <td>8</td>\n",
       "      <td>319481.0</td>\n",
       "      <td>138000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>130515.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>24813.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26653</td>\n",
       "      <td>3</td>\n",
       "      <td>166357.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>68526.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>23112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30210</td>\n",
       "      <td>13</td>\n",
       "      <td>320552.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>130801.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2003-12-01</td>\n",
       "      <td>25358.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27792</td>\n",
       "      <td>5</td>\n",
       "      <td>166210.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>68837.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2003-12-01</td>\n",
       "      <td>23828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30518</td>\n",
       "      <td>16</td>\n",
       "      <td>321802.0</td>\n",
       "      <td>138000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>131883.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2004-12-01</td>\n",
       "      <td>26089.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29088</td>\n",
       "      <td>14</td>\n",
       "      <td>165610.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>68899.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2004-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30795</td>\n",
       "      <td>20</td>\n",
       "      <td>323723.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>132856.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2005-12-01</td>\n",
       "      <td>26680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28728</td>\n",
       "      <td>17</td>\n",
       "      <td>166275.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>69261.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2005-12-01</td>\n",
       "      <td>27033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31652</td>\n",
       "      <td>27</td>\n",
       "      <td>327541.0</td>\n",
       "      <td>136000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>133902.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>26549.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28660</td>\n",
       "      <td>21</td>\n",
       "      <td>167157.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>69529.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>26071.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30923</td>\n",
       "      <td>29</td>\n",
       "      <td>330801.0</td>\n",
       "      <td>138000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>134941.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>30200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31994</td>\n",
       "      <td>20</td>\n",
       "      <td>169031.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>69835.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>27436.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33007</td>\n",
       "      <td>31</td>\n",
       "      <td>334837.0</td>\n",
       "      <td>136000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>135429.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>29396.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31795</td>\n",
       "      <td>25</td>\n",
       "      <td>172452.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>70551.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>27978.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34468</td>\n",
       "      <td>31</td>\n",
       "      <td>339212.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>136680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2009-12-01</td>\n",
       "      <td>30973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33126</td>\n",
       "      <td>33</td>\n",
       "      <td>177580.0</td>\n",
       "      <td>47000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>70839.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2009-12-01</td>\n",
       "      <td>30496.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35013</td>\n",
       "      <td>33</td>\n",
       "      <td>345829.0</td>\n",
       "      <td>143000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>137769.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>28527.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32996</td>\n",
       "      <td>28</td>\n",
       "      <td>182838.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>70946.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34077</td>\n",
       "      <td>33</td>\n",
       "      <td>351438.0</td>\n",
       "      <td>141000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>138616.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>28201.0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>33568</td>\n",
       "      <td>30</td>\n",
       "      <td>187029.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>71079.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>30237.0</td>\n",
       "      <td>7.43</td>\n",
       "      <td>33062</td>\n",
       "      <td>34</td>\n",
       "      <td>357538.0</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>139346.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>33131.0</td>\n",
       "      <td>7.09</td>\n",
       "      <td>37059</td>\n",
       "      <td>27</td>\n",
       "      <td>190560.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>71431.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>29594.0</td>\n",
       "      <td>7.28</td>\n",
       "      <td>33044</td>\n",
       "      <td>33</td>\n",
       "      <td>363956.0</td>\n",
       "      <td>154000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>141461.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>32248.0</td>\n",
       "      <td>7.01</td>\n",
       "      <td>37214</td>\n",
       "      <td>25</td>\n",
       "      <td>194352.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>71937.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>29353.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>33766</td>\n",
       "      <td>36</td>\n",
       "      <td>369088.0</td>\n",
       "      <td>159000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>142835.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>32698.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>36323</td>\n",
       "      <td>23</td>\n",
       "      <td>198294.0</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>72668.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>31162.0</td>\n",
       "      <td>7.54</td>\n",
       "      <td>34936</td>\n",
       "      <td>38</td>\n",
       "      <td>374915.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>143948.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>33018.0</td>\n",
       "      <td>7.45</td>\n",
       "      <td>36705</td>\n",
       "      <td>19</td>\n",
       "      <td>201979.0</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>73182.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>30900.0</td>\n",
       "      <td>7.53</td>\n",
       "      <td>34730</td>\n",
       "      <td>37</td>\n",
       "      <td>379691.0</td>\n",
       "      <td>168000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>145272.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>30994.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>37959</td>\n",
       "      <td>25</td>\n",
       "      <td>206460.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>73914.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>32623.0</td>\n",
       "      <td>7.47</td>\n",
       "      <td>35315</td>\n",
       "      <td>37</td>\n",
       "      <td>386083.0</td>\n",
       "      <td>169000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>146730.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>28553.0</td>\n",
       "      <td>7.66</td>\n",
       "      <td>32093</td>\n",
       "      <td>25</td>\n",
       "      <td>210711.0</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>74510.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>32143.0</td>\n",
       "      <td>7.63</td>\n",
       "      <td>36818</td>\n",
       "      <td>37</td>\n",
       "      <td>387803.0</td>\n",
       "      <td>176000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>148529.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>29995.0</td>\n",
       "      <td>7.52</td>\n",
       "      <td>32671</td>\n",
       "      <td>24</td>\n",
       "      <td>211998.0</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>74923.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>29927.0</td>\n",
       "      <td>7.55</td>\n",
       "      <td>36776</td>\n",
       "      <td>35</td>\n",
       "      <td>392140.0</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>150737.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>28738.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>31624.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           code                  area        date  median_salary  \\\n",
       "1     E09000002  barking and dagenham  1999-12-01        21480.0   \n",
       "2     E09000003                barnet  1999-12-01        19568.0   \n",
       "52    E09000002  barking and dagenham  2000-12-01        22618.0   \n",
       "53    E09000003                barnet  2000-12-01        21761.0   \n",
       "103   E09000002  barking and dagenham  2001-12-01        22323.0   \n",
       "104   E09000003                barnet  2001-12-01        20916.0   \n",
       "154   E09000002  barking and dagenham  2002-12-01        24813.0   \n",
       "155   E09000003                barnet  2002-12-01        23112.0   \n",
       "205   E09000002  barking and dagenham  2003-12-01        25358.0   \n",
       "206   E09000003                barnet  2003-12-01        23828.0   \n",
       "256   E09000002  barking and dagenham  2004-12-01        26089.0   \n",
       "257   E09000003                barnet  2004-12-01            NaN   \n",
       "307   E09000002  barking and dagenham  2005-12-01        26680.0   \n",
       "308   E09000003                barnet  2005-12-01        27033.0   \n",
       "358   E09000002  barking and dagenham  2006-12-01        26549.0   \n",
       "359   E09000003                barnet  2006-12-01        26071.0   \n",
       "409   E09000002  barking and dagenham  2007-12-01        30200.0   \n",
       "410   E09000003                barnet  2007-12-01        27436.0   \n",
       "460   E09000002  barking and dagenham  2008-12-01        29396.0   \n",
       "461   E09000003                barnet  2008-12-01        27978.0   \n",
       "511   E09000002  barking and dagenham  2009-12-01        30973.0   \n",
       "512   E09000003                barnet  2009-12-01        30496.0   \n",
       "562   E09000002  barking and dagenham  2010-12-01        28527.0   \n",
       "563   E09000003                barnet  2010-12-01        30000.0   \n",
       "613   E09000002  barking and dagenham  2011-12-01        28201.0   \n",
       "614   E09000003                barnet  2011-12-01        30237.0   \n",
       "664   E09000002  barking and dagenham  2012-12-01        33131.0   \n",
       "665   E09000003                barnet  2012-12-01        29594.0   \n",
       "715   E09000002  barking and dagenham  2013-12-01        32248.0   \n",
       "716   E09000003                barnet  2013-12-01        29353.0   \n",
       "766   E09000002  barking and dagenham  2014-12-01        32698.0   \n",
       "767   E09000003                barnet  2014-12-01        31162.0   \n",
       "817   E09000002  barking and dagenham  2015-12-01        33018.0   \n",
       "818   E09000003                barnet  2015-12-01        30900.0   \n",
       "868   E09000002  barking and dagenham  2016-12-01        30994.0   \n",
       "869   E09000003                barnet  2016-12-01        32623.0   \n",
       "919   E09000002  barking and dagenham  2017-12-01        28553.0   \n",
       "920   E09000003                barnet  2017-12-01        32143.0   \n",
       "970   E09000002  barking and dagenham  2018-12-01        29995.0   \n",
       "971   E09000003                barnet  2018-12-01        29927.0   \n",
       "1021  E09000002  barking and dagenham  2019-12-01        28738.0   \n",
       "1022  E09000003                barnet  2019-12-01        31624.0   \n",
       "\n",
       "      life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "1                   NaN       23620             3         162444.0   \n",
       "2                   NaN       23128             8         313469.0   \n",
       "52                  NaN       24696             4         163893.0   \n",
       "53                  NaN       25755             8         315784.0   \n",
       "103                 NaN       26050             3         165654.0   \n",
       "104                 NaN       26068             8         319481.0   \n",
       "154                 NaN       26653             3         166357.0   \n",
       "155                 NaN       30210            13         320552.0   \n",
       "205                 NaN       27792             5         166210.0   \n",
       "206                 NaN       30518            16         321802.0   \n",
       "256                 NaN       29088            14         165610.0   \n",
       "257                 NaN       30795            20         323723.0   \n",
       "307                 NaN       28728            17         166275.0   \n",
       "308                 NaN       31652            27         327541.0   \n",
       "358                 NaN       28660            21         167157.0   \n",
       "359                 NaN       30923            29         330801.0   \n",
       "409                 NaN       31994            20         169031.0   \n",
       "410                 NaN       33007            31         334837.0   \n",
       "460                 NaN       31795            25         172452.0   \n",
       "461                 NaN       34468            31         339212.0   \n",
       "511                 NaN       33126            33         177580.0   \n",
       "512                 NaN       35013            33         345829.0   \n",
       "562                 NaN       32996            28         182838.0   \n",
       "563                 NaN       34077            33         351438.0   \n",
       "613                7.05       33568            30         187029.0   \n",
       "614                7.43       33062            34         357538.0   \n",
       "664                7.09       37059            27         190560.0   \n",
       "665                7.28       33044            33         363956.0   \n",
       "715                7.01       37214            25         194352.0   \n",
       "716                7.40       33766            36         369088.0   \n",
       "766                7.32       36323            23         198294.0   \n",
       "767                7.54       34936            38         374915.0   \n",
       "817                7.45       36705            19         201979.0   \n",
       "818                7.53       34730            37         379691.0   \n",
       "868                7.50       37959            25         206460.0   \n",
       "869                7.47       35315            37         386083.0   \n",
       "919                7.66       32093            25         210711.0   \n",
       "920                7.63       36818            37         387803.0   \n",
       "970                7.52       32671            24         211998.0   \n",
       "971                7.55       36776            35         392140.0   \n",
       "1021                NaN       32010           NaN              NaN   \n",
       "1022                NaN       37328           NaN              NaN   \n",
       "\n",
       "      number_of_jobs  area_size  no_of_houses  borough_flag  year  \n",
       "1                NaN        NaN           NaN             1  1999  \n",
       "2                NaN        NaN           NaN             1  1999  \n",
       "52           57000.0        NaN           NaN             1  2000  \n",
       "53          138000.0        NaN           NaN             1  2000  \n",
       "103          54000.0     3780.0       68298.0             1  2001  \n",
       "104         138000.0     8675.0      130515.0             1  2001  \n",
       "154          52000.0     3780.0       68526.0             1  2002  \n",
       "155         135000.0     8675.0      130801.0             1  2002  \n",
       "205          55000.0     3780.0       68837.0             1  2003  \n",
       "206         138000.0     8675.0      131883.0             1  2003  \n",
       "256          53000.0     3780.0       68899.0             1  2004  \n",
       "257         135000.0     8675.0      132856.0             1  2004  \n",
       "307          53000.0     3780.0       69261.0             1  2005  \n",
       "308         136000.0     8675.0      133902.0             1  2005  \n",
       "358          51000.0     3780.0       69529.0             1  2006  \n",
       "359         138000.0     8675.0      134941.0             1  2006  \n",
       "409          52000.0     3780.0       69835.0             1  2007  \n",
       "410         136000.0     8675.0      135429.0             1  2007  \n",
       "460          53000.0     3780.0       70551.0             1  2008  \n",
       "461         140000.0     8675.0      136680.0             1  2008  \n",
       "511          47000.0     3780.0       70839.0             1  2009  \n",
       "512         143000.0     8675.0      137769.0             1  2009  \n",
       "562          51000.0     3780.0       70946.0             1  2010  \n",
       "563         141000.0     8675.0      138616.0             1  2010  \n",
       "613          54000.0     3780.0       71079.0             1  2011  \n",
       "614         147000.0     8675.0      139346.0             1  2011  \n",
       "664          55000.0     3780.0       71431.0             1  2012  \n",
       "665         154000.0     8675.0      141461.0             1  2012  \n",
       "715          54000.0     3780.0       71937.0             1  2013  \n",
       "716         159000.0     8675.0      142835.0             1  2013  \n",
       "766          59000.0     3780.0       72668.0             1  2014  \n",
       "767         165000.0     8675.0      143948.0             1  2014  \n",
       "817          62000.0     3780.0       73182.0             1  2015  \n",
       "818         168000.0     8675.0      145272.0             1  2015  \n",
       "868          63000.0     3780.0       73914.0             1  2016  \n",
       "869         169000.0     8675.0      146730.0             1  2016  \n",
       "919          66000.0     3780.0       74510.0             1  2017  \n",
       "920         176000.0     8675.0      148529.0             1  2017  \n",
       "970          66000.0     3780.0       74923.0             1  2018  \n",
       "971         170000.0     8675.0      150737.0             1  2018  \n",
       "1021             NaN        NaN           NaN             1  2019  \n",
       "1022             NaN        NaN           NaN             1  2019  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_ba = housing_london[housing_london['area'].str.startswith('ba')]\n",
    "display (filter_ba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrSsOstK8Z9_"
   },
   "source": [
    "### Exercise 5\n",
    "---\n",
    "Filter the data for all areas ending with 'ham', for the year 2000\n",
    "\n",
    "**Test output**:  \n",
    "4 rows (barking and dagenham, hammersmith and fulham, lewisham, newham)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "lMJckNo-ab3z"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>22618.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24696</td>\n",
       "      <td>4</td>\n",
       "      <td>163893.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>hammersmith and fulham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>25264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28742</td>\n",
       "      <td>8</td>\n",
       "      <td>164393.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>E09000023</td>\n",
       "      <td>lewisham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>22357.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22659</td>\n",
       "      <td>5</td>\n",
       "      <td>252106.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>E09000025</td>\n",
       "      <td>newham</td>\n",
       "      <td>2000-12-01</td>\n",
       "      <td>19437.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21609</td>\n",
       "      <td>3</td>\n",
       "      <td>245463.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         code                    area        date  median_salary  \\\n",
       "52  E09000002    barking and dagenham  2000-12-01        22618.0   \n",
       "63  E09000013  hammersmith and fulham  2000-12-01        25264.0   \n",
       "73  E09000023                lewisham  2000-12-01        22357.0   \n",
       "75  E09000025                  newham  2000-12-01        19437.0   \n",
       "\n",
       "    life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "52                NaN       24696             4         163893.0   \n",
       "63                NaN       28742             8         164393.0   \n",
       "73                NaN       22659             5         252106.0   \n",
       "75                NaN       21609             3         245463.0   \n",
       "\n",
       "    number_of_jobs  area_size  no_of_houses  borough_flag  year  \n",
       "52         57000.0        NaN           NaN             1  2000  \n",
       "63        120000.0        NaN           NaN             1  2000  \n",
       "73         76000.0        NaN           NaN             1  2000  \n",
       "75         79000.0        NaN           NaN             1  2000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = housing_london[(housing_london[\"area\"].str.endswith(\"ham\")) & (housing_london[\"date\"].str.contains(\"2000\"))]\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_niKyF39X4q"
   },
   "source": [
    "### Exercise 6 - new data set\n",
    "---\n",
    "\n",
    "Use the data set here:  https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\n",
    "\n",
    "Read the data from the sheet 'Skill Migration'  \n",
    "\n",
    "Inspect the data, then create a new dataframe with the following changes:\n",
    "\n",
    "1.  Remove the word 'Skills' from the 'skill_group_category' column  \n",
    "2.  Convert country_code to uppercase  \n",
    "3.  Filter for regions containing 'Asia'\n",
    "4.  Remove the skill_group_id and the wb_income columns\n",
    "\n",
    "**Test output**:  \n",
    "9969 rows × 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "UGfVBX1FCjZj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>wb_region</th>\n",
       "      <th>skill_group_category</th>\n",
       "      <th>skill_group_name</th>\n",
       "      <th>net_per_10K_2015</th>\n",
       "      <th>net_per_10K_2016</th>\n",
       "      <th>net_per_10K_2017</th>\n",
       "      <th>net_per_10K_2018</th>\n",
       "      <th>net_per_10K_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Information Management</td>\n",
       "      <td>-791.59</td>\n",
       "      <td>-705.88</td>\n",
       "      <td>-550.04</td>\n",
       "      <td>-680.92</td>\n",
       "      <td>-1208.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Business</td>\n",
       "      <td>Operational Efficiency</td>\n",
       "      <td>-1610.25</td>\n",
       "      <td>-933.55</td>\n",
       "      <td>-776.06</td>\n",
       "      <td>-532.22</td>\n",
       "      <td>-790.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Specialized Industry</td>\n",
       "      <td>National Security</td>\n",
       "      <td>-1731.45</td>\n",
       "      <td>-769.68</td>\n",
       "      <td>-756.59</td>\n",
       "      <td>-600.44</td>\n",
       "      <td>-767.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Software Testing</td>\n",
       "      <td>-957.50</td>\n",
       "      <td>-828.54</td>\n",
       "      <td>-964.73</td>\n",
       "      <td>-406.50</td>\n",
       "      <td>-739.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Specialized Industry</td>\n",
       "      <td>Navy</td>\n",
       "      <td>-1510.71</td>\n",
       "      <td>-841.17</td>\n",
       "      <td>-842.32</td>\n",
       "      <td>-581.71</td>\n",
       "      <td>-718.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17371</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Specialized Industry</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>658.89</td>\n",
       "      <td>291.89</td>\n",
       "      <td>-271.00</td>\n",
       "      <td>219.20</td>\n",
       "      <td>166.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17372</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Specialized Industry</td>\n",
       "      <td>Cooking</td>\n",
       "      <td>83.81</td>\n",
       "      <td>236.02</td>\n",
       "      <td>-42.85</td>\n",
       "      <td>238.90</td>\n",
       "      <td>180.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Business</td>\n",
       "      <td>Sales Leads</td>\n",
       "      <td>511.16</td>\n",
       "      <td>98.13</td>\n",
       "      <td>-355.91</td>\n",
       "      <td>133.89</td>\n",
       "      <td>181.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Disruptive Tech</td>\n",
       "      <td>Aerospace Engineering</td>\n",
       "      <td>410.02</td>\n",
       "      <td>42.71</td>\n",
       "      <td>-222.09</td>\n",
       "      <td>138.03</td>\n",
       "      <td>256.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Business</td>\n",
       "      <td>Revenue Analysis</td>\n",
       "      <td>315.68</td>\n",
       "      <td>158.12</td>\n",
       "      <td>101.89</td>\n",
       "      <td>277.98</td>\n",
       "      <td>267.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9969 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country_code country_name            wb_region   skill_group_category  \\\n",
       "0               AF  Afghanistan           South Asia                  Tech    \n",
       "1               AF  Afghanistan           South Asia              Business    \n",
       "2               AF  Afghanistan           South Asia  Specialized Industry    \n",
       "3               AF  Afghanistan           South Asia                  Tech    \n",
       "4               AF  Afghanistan           South Asia  Specialized Industry    \n",
       "...            ...          ...                  ...                    ...   \n",
       "17371           VN      Vietnam  East Asia & Pacific  Specialized Industry    \n",
       "17372           VN      Vietnam  East Asia & Pacific  Specialized Industry    \n",
       "17373           VN      Vietnam  East Asia & Pacific              Business    \n",
       "17374           VN      Vietnam  East Asia & Pacific       Disruptive Tech    \n",
       "17375           VN      Vietnam  East Asia & Pacific              Business    \n",
       "\n",
       "             skill_group_name  net_per_10K_2015  net_per_10K_2016  \\\n",
       "0      Information Management           -791.59           -705.88   \n",
       "1      Operational Efficiency          -1610.25           -933.55   \n",
       "2           National Security          -1731.45           -769.68   \n",
       "3            Software Testing           -957.50           -828.54   \n",
       "4                        Navy          -1510.71           -841.17   \n",
       "...                       ...               ...               ...   \n",
       "17371               Air Force            658.89            291.89   \n",
       "17372                 Cooking             83.81            236.02   \n",
       "17373             Sales Leads            511.16             98.13   \n",
       "17374   Aerospace Engineering            410.02             42.71   \n",
       "17375        Revenue Analysis            315.68            158.12   \n",
       "\n",
       "       net_per_10K_2017  net_per_10K_2018  net_per_10K_2019  \n",
       "0               -550.04           -680.92          -1208.79  \n",
       "1               -776.06           -532.22           -790.09  \n",
       "2               -756.59           -600.44           -767.64  \n",
       "3               -964.73           -406.50           -739.51  \n",
       "4               -842.32           -581.71           -718.64  \n",
       "...                 ...               ...               ...  \n",
       "17371           -271.00            219.20            166.99  \n",
       "17372            -42.85            238.90            180.90  \n",
       "17373           -355.91            133.89            181.47  \n",
       "17374           -222.09            138.03            256.55  \n",
       "17375            101.89            277.98            267.58  \n",
       "\n",
       "[9969 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read data\n",
    "url=\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
    "migration_data = pd.read_excel(url, sheet_name='Skill Migration')\n",
    "#delete unnamed columns ~ inverts the selection ^ is a regrex statement to say column starts with \n",
    "# migration_data = migration_data.loc[:, ~migration_data.columns.str.contains('^Unnamed')]\n",
    "migration_data.drop(migration_data.filter(regex=\"Unnamed\"),axis=1, inplace=True)\n",
    "\n",
    "#1. Remove the word 'Skills' from the 'skill_group_category' column \n",
    "migration_data['skill_group_category'] = migration_data['skill_group_category'].str.replace('Skills', '')#1\n",
    "#2. Convert country_code to uppercase \n",
    "migration_data['country_code'] = migration_data['country_code'].str.upper()#2\n",
    "#3. Filter for regions containing 'Asia' - needs to be in \"\"\n",
    "migration_data = migration_data[migration_data['wb_region'].str.contains(\"Asia\")]\n",
    "#4. Remove the skill_group_id and the wb_income columns\n",
    "migration_data = migration_data.drop(columns = ['skill_group_id', 'wb_income'])\n",
    "\n",
    "display (migration_data)\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVUE_rVkCj4g"
   },
   "source": [
    "### Exercise 7 - a data cleaning function\n",
    "\n",
    "Create a function called **clean_data(df)** that perform the same actions as in Exercise 6, and will *return* the cleaned data set\n",
    "\n",
    "Format:\n",
    "\n",
    "```\n",
    "def clean_data(df):\n",
    "  # code to clean the data as in exerise 6, then return the final dataframe\n",
    "\n",
    "cleaned_data = clean_data(migration_data)\n",
    "```\n",
    "**Test output:**  \n",
    "9969 rows × 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "kEFpr4_5EKZ6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>wb_region</th>\n",
       "      <th>skill_group_category</th>\n",
       "      <th>skill_group_name</th>\n",
       "      <th>net_per_10K_2015</th>\n",
       "      <th>net_per_10K_2016</th>\n",
       "      <th>net_per_10K_2017</th>\n",
       "      <th>net_per_10K_2018</th>\n",
       "      <th>net_per_10K_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Information Management</td>\n",
       "      <td>-791.59</td>\n",
       "      <td>-705.88</td>\n",
       "      <td>-550.04</td>\n",
       "      <td>-680.92</td>\n",
       "      <td>-1208.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Business</td>\n",
       "      <td>Operational Efficiency</td>\n",
       "      <td>-1610.25</td>\n",
       "      <td>-933.55</td>\n",
       "      <td>-776.06</td>\n",
       "      <td>-532.22</td>\n",
       "      <td>-790.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Specialized Industry</td>\n",
       "      <td>National Security</td>\n",
       "      <td>-1731.45</td>\n",
       "      <td>-769.68</td>\n",
       "      <td>-756.59</td>\n",
       "      <td>-600.44</td>\n",
       "      <td>-767.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Software Testing</td>\n",
       "      <td>-957.50</td>\n",
       "      <td>-828.54</td>\n",
       "      <td>-964.73</td>\n",
       "      <td>-406.50</td>\n",
       "      <td>-739.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>Specialized Industry</td>\n",
       "      <td>Navy</td>\n",
       "      <td>-1510.71</td>\n",
       "      <td>-841.17</td>\n",
       "      <td>-842.32</td>\n",
       "      <td>-581.71</td>\n",
       "      <td>-718.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17371</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Specialized Industry</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>658.89</td>\n",
       "      <td>291.89</td>\n",
       "      <td>-271.00</td>\n",
       "      <td>219.20</td>\n",
       "      <td>166.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17372</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Specialized Industry</td>\n",
       "      <td>Cooking</td>\n",
       "      <td>83.81</td>\n",
       "      <td>236.02</td>\n",
       "      <td>-42.85</td>\n",
       "      <td>238.90</td>\n",
       "      <td>180.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Business</td>\n",
       "      <td>Sales Leads</td>\n",
       "      <td>511.16</td>\n",
       "      <td>98.13</td>\n",
       "      <td>-355.91</td>\n",
       "      <td>133.89</td>\n",
       "      <td>181.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Disruptive Tech</td>\n",
       "      <td>Aerospace Engineering</td>\n",
       "      <td>410.02</td>\n",
       "      <td>42.71</td>\n",
       "      <td>-222.09</td>\n",
       "      <td>138.03</td>\n",
       "      <td>256.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "      <td>Business</td>\n",
       "      <td>Revenue Analysis</td>\n",
       "      <td>315.68</td>\n",
       "      <td>158.12</td>\n",
       "      <td>101.89</td>\n",
       "      <td>277.98</td>\n",
       "      <td>267.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9969 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country_code country_name            wb_region   skill_group_category  \\\n",
       "0               AF  Afghanistan           South Asia                  Tech    \n",
       "1               AF  Afghanistan           South Asia              Business    \n",
       "2               AF  Afghanistan           South Asia  Specialized Industry    \n",
       "3               AF  Afghanistan           South Asia                  Tech    \n",
       "4               AF  Afghanistan           South Asia  Specialized Industry    \n",
       "...            ...          ...                  ...                    ...   \n",
       "17371           VN      Vietnam  East Asia & Pacific  Specialized Industry    \n",
       "17372           VN      Vietnam  East Asia & Pacific  Specialized Industry    \n",
       "17373           VN      Vietnam  East Asia & Pacific              Business    \n",
       "17374           VN      Vietnam  East Asia & Pacific       Disruptive Tech    \n",
       "17375           VN      Vietnam  East Asia & Pacific              Business    \n",
       "\n",
       "             skill_group_name  net_per_10K_2015  net_per_10K_2016  \\\n",
       "0      Information Management           -791.59           -705.88   \n",
       "1      Operational Efficiency          -1610.25           -933.55   \n",
       "2           National Security          -1731.45           -769.68   \n",
       "3            Software Testing           -957.50           -828.54   \n",
       "4                        Navy          -1510.71           -841.17   \n",
       "...                       ...               ...               ...   \n",
       "17371               Air Force            658.89            291.89   \n",
       "17372                 Cooking             83.81            236.02   \n",
       "17373             Sales Leads            511.16             98.13   \n",
       "17374   Aerospace Engineering            410.02             42.71   \n",
       "17375        Revenue Analysis            315.68            158.12   \n",
       "\n",
       "       net_per_10K_2017  net_per_10K_2018  net_per_10K_2019  \n",
       "0               -550.04           -680.92          -1208.79  \n",
       "1               -776.06           -532.22           -790.09  \n",
       "2               -756.59           -600.44           -767.64  \n",
       "3               -964.73           -406.50           -739.51  \n",
       "4               -842.32           -581.71           -718.64  \n",
       "...                 ...               ...               ...  \n",
       "17371           -271.00            219.20            166.99  \n",
       "17372            -42.85            238.90            180.90  \n",
       "17373           -355.91            133.89            181.47  \n",
       "17374           -222.09            138.03            256.55  \n",
       "17375            101.89            277.98            267.58  \n",
       "\n",
       "[9969 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    #delete unnamed columns ~ inverts the selection ^ is a regrex statement to say column starts with \n",
    "    df.drop(df.filter(regex=\"Unnamed\"),axis=1, inplace=True)\n",
    "    #1. Remove the word 'Skills' from the 'skill_group_category' column \n",
    "    df['skill_group_category'] = df['skill_group_category'].str.replace('Skills', '')#1\n",
    "    #2. Convert country_code to uppercase \n",
    "    df['country_code'] = df['country_code'].str.upper()#2\n",
    "    #3. Filter for regions containing 'Asia' - needs to be in \"\"\n",
    "    df = df[df['wb_region'].str.contains(\"Asia\")]\n",
    "    #4. Remove the skill_group_id and the wb_income columns\n",
    "    df = df.drop(columns = ['skill_group_id', 'wb_income'])\n",
    "    display (df)\n",
    "    \n",
    "url=\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
    "migration_data = pd.read_excel(url, sheet_name='Skill Migration')\n",
    "cleaned_data = clean_data(migration_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_i4oQaoEKoY"
   },
   "source": [
    "### Exercise 8\n",
    "---\n",
    "\n",
    "Write a function that will rename the net_per_10K_year columns to be just the year and will replace the 'z' (as in 'specialized') with 's' to Anglicise the spelling. The function should return the cleaned data.  \n",
    "\n",
    "Hint:  for column names, you can get the name as a string, then use find() to see if 'net_per_10K_' is in the string (the result will not be -1 if it is there), then you can replace the column name\n",
    "\n",
    "**Test output**:  \n",
    "17617 rows × 12 columns, with z replace by s in Specialized  \n",
    "Column names: country_code\tcountry_name\twb_income\twb_region\tskill_group_id\tskill_group_category\tskill_group_name\t2015\t2016\t2017\t2018\t2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "AEWS56l4JKx3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>wb_income</th>\n",
       "      <th>wb_region</th>\n",
       "      <th>skill_group_id</th>\n",
       "      <th>skill_group_category</th>\n",
       "      <th>skill_group_name</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2549</td>\n",
       "      <td>Tech Skills</td>\n",
       "      <td>Information Management</td>\n",
       "      <td>-791.59</td>\n",
       "      <td>-705.88</td>\n",
       "      <td>-550.04</td>\n",
       "      <td>-680.92</td>\n",
       "      <td>-1208.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>af</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>2608</td>\n",
       "      <td>Business Skills</td>\n",
       "      <td>Operational Efficiency</td>\n",
       "      <td>-1610.25</td>\n",
       "      <td>-933.55</td>\n",
       "      <td>-776.06</td>\n",
       "      <td>-532.22</td>\n",
       "      <td>-790.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>3806</td>\n",
       "      <td>Specialised Industry Skills</td>\n",
       "      <td>National Security</td>\n",
       "      <td>-1731.45</td>\n",
       "      <td>-769.68</td>\n",
       "      <td>-756.59</td>\n",
       "      <td>-600.44</td>\n",
       "      <td>-767.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>50321</td>\n",
       "      <td>Tech Skills</td>\n",
       "      <td>Software Testing</td>\n",
       "      <td>-957.50</td>\n",
       "      <td>-828.54</td>\n",
       "      <td>-964.73</td>\n",
       "      <td>-406.50</td>\n",
       "      <td>-739.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Low income</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>1606</td>\n",
       "      <td>Specialised Industry Skills</td>\n",
       "      <td>Navy</td>\n",
       "      <td>-1510.71</td>\n",
       "      <td>-841.17</td>\n",
       "      <td>-842.32</td>\n",
       "      <td>-581.71</td>\n",
       "      <td>-718.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code country_name   wb_income   wb_region  skill_group_id  \\\n",
       "0           af  Afghanistan  Low income  South Asia            2549   \n",
       "1           af  Afghanistan  Low income  South Asia            2608   \n",
       "2           af  Afghanistan  Low income  South Asia            3806   \n",
       "3           af  Afghanistan  Low income  South Asia           50321   \n",
       "4           af  Afghanistan  Low income  South Asia            1606   \n",
       "\n",
       "          skill_group_category        skill_group_name     2015    2016  \\\n",
       "0                  Tech Skills  Information Management  -791.59 -705.88   \n",
       "1              Business Skills  Operational Efficiency -1610.25 -933.55   \n",
       "2  Specialised Industry Skills       National Security -1731.45 -769.68   \n",
       "3                  Tech Skills        Software Testing  -957.50 -828.54   \n",
       "4  Specialised Industry Skills                    Navy -1510.71 -841.17   \n",
       "\n",
       "     2017    2018     2019  \n",
       "0 -550.04 -680.92 -1208.79  \n",
       "1 -776.06 -532.22  -790.09  \n",
       "2 -756.59 -600.44  -767.64  \n",
       "3 -964.73 -406.50  -739.51  \n",
       "4 -842.32 -581.71  -718.64  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# column_names =list(migration_data.columns)\n",
    "def rename(df):\n",
    "    #delete unnamed columns ~ inverts the selection ^ is a regrex statement to say column starts with \n",
    "    df.drop(df.filter(regex=\"Unnamed\"),axis=1, inplace=True)\n",
    "    # replace column strings\n",
    "    df.columns = df.columns.str.replace(\"net_per_10K_\", \"\")\n",
    "    # update values using regular expression\n",
    "    df.replace(\"Specialized\",\"Specialised\", regex=True, inplace=True)\n",
    "\n",
    "\n",
    "url=\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
    "migration_data = pd.read_excel(url, sheet_name='Skill Migration')\n",
    "rename(migration_data)  \n",
    "# display(column_names)\n",
    "migration_data.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def clean_data(df):\n",
    "    \n",
    "#     df.str.replace('*net_per_10K_*', '', regex=True)\n",
    "# # for column names, you can get the name as a string, then use find() to see if 'net_per_10K_' is in the string (the result will not be -1 if it is there), then you can replace the column name    \n",
    "# #     df.columns = df.columns.astype(str)\n",
    "# #     if df.str.find('net_per_10K_') == -1:\n",
    "# #         df.str.replace('net_per_10K_', '')\n",
    "\n",
    "#     return df\n",
    "\n",
    "    \n",
    "# clean_data(migration_data)\n",
    "\n",
    "#display (migration_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pqc9I5VpJLpR"
   },
   "source": [
    "### Exercise 9\n",
    "---\n",
    "\n",
    "Read the 'Country Migration' sheet.\n",
    "\n",
    "Write a function that will:  \n",
    "*  convert the country codes to upper case  \n",
    "*  drop the lat and long columns for both base and target  \n",
    "*  rename the net_per_10K_year columns to year only  \n",
    "*  filter for base_country_wb_region contains 'Africa' and target_country_wb_region contains Asia  \n",
    "\n",
    "**Test output**:  \n",
    "```\n",
    "base_country_code\tbase_country_name\tbase_country_wb_income\tbase_country_wb_region\ttarget_country_code\ttarget_country_name\ttarget_country_wb_income\ttarget_country_wb_region\t2015\t2016\t2017\t2018\t2019\n",
    "0\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAF\tAfghanistan\tLow Income\tSouth Asia\t0.19\t0.16\t0.11\t-0.05\t-0.02\n",
    "4\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAM\tArmenia\tUpper Middle Income\tEurope & Central Asia\t0.10\t0.05\t0.03\t-0.01\t0.02\n",
    "5\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAU\tAustralia\tHigh Income\tEast Asia & Pacific\t-1.06\t-3.31\t-4.01\t-4.58\t-4.09\n",
    "6\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAT\tAustria\tHigh Income\tEurope & Central Asia\t0.11\t-0.08\t-0.07\t-0.05\t-0.16\n",
    "7\tAE\tUnited Arab Emirates\tHigh Income\tMiddle East & North Africa\tAZ\tAzerbaijan\tUpper Middle Income\tEurope & Central Asia\t0.24\t0.25\t0.10\t0.05\t0.04\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "4132\tZM\tZambia\tLower Middle Income\tSub-Saharan Africa\tGB\tUnited Kingdom\tHigh Income\tEurope & Central Asia\t43.27\t27.60\t7.88\t6.90\t3.68\n",
    "4135\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tAU\tAustralia\tHigh Income\tEast Asia & Pacific\t-1.31\t-2.33\t-2.10\t-2.08\t-1.84\n",
    "4138\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tIS\tIceland\tHigh Income\tEurope & Central Asia\t8.52\t6.22\t2.35\t1.81\t0.97\n",
    "4142\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tNO\tNorway\tHigh Income\tEurope & Central Asia\t2.88\t6.46\t2.10\t0.33\t-0.13\n",
    "4145\tZW\tZimbabwe\tLow Income\tSub-Saharan Africa\tGB\tUnited Kingdom\tHigh Income\tEurope & Central Asia\t3.91\t4.66\t0.74\t-0.66\t-1.97\n",
    "478 rows × 13 columns\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "jYu6n_jF9v1Y"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-ec8a69f8be68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#df['country_code'] = df['country_code'].str.upper()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m    \u001b[1;31m# drop the lat and long columns for both base and target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcountry_migration\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcountry_migration\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_lat'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_long'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#df.drop(labels='weight', level=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'column' is not defined"
     ]
    }
   ],
   "source": [
    "url=\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
    "country_migration = pd.read_excel(url, sheet_name='Country Migration')\n",
    "\n",
    "\n",
    "   # convert the country codes to upper case\n",
    "#df['country_code'] = df['country_code'].str.upper()\n",
    "   # drop the lat and long columns for both base and target\n",
    "country_migration[country_migration.str.contains('_lat','_long' ).drop]\n",
    "#df.drop(labels='weight', level=1)\n",
    "    \n",
    "    #rename the net_per_10K_year columns to year only\n",
    "    \n",
    "    #filter for base_country_wb_region contains 'Africa' and target_country_wb_region contains Asia\n",
    "#df = df[df['base_country_wb_region'].str.contains(\"Africa\") and df[df['target_country_wb_region'].str.contains(\"Asia\")]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V6mNsfsNrsd"
   },
   "source": [
    "### Exercise 10\n",
    "---\n",
    "\n",
    "Read the data from file 'https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv'.\n",
    "\n",
    "Write a function that will return a new dataframe with just the married women listed, surname only.\n",
    "\n",
    "**Test output**:  \n",
    "```\n",
    "\tPassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked\n",
    "1\t2\t1\t1\tCumings\tfemale\t38.0\t1\t0\tPC 17599\t71.2833\tC85\tC\n",
    "3\t4\t1\t1\tFutrelle\tfemale\t35.0\t1\t0\t113803\t53.1000\tC123\tS\n",
    "8\t9\t1\t3\tJohnson\tfemale\t27.0\t0\t2\t347742\t11.1333\tNaN\tS\n",
    "9\t10\t1\t2\tNasser\tfemale\t14.0\t1\t0\t237736\t30.0708\tNaN\tC\n",
    "15\t16\t1\t2\tHewlett\tfemale\t55.0\t0\t0\t248706\t16.0000\tNaN\tS\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "871\t872\t1\t1\tBeckwith\tfemale\t47.0\t1\t1\t11751\t52.5542\tD35\tS\n",
    "874\t875\t1\t2\tAbelson\tfemale\t28.0\t1\t0\tP/PP 3381\t24.0000\tNaN\tC\n",
    "879\t880\t1\t1\tPotter\tfemale\t56.0\t0\t1\t11767\t83.1583\tC50\tC\n",
    "880\t881\t1\t2\tShelley\tfemale\t25.0\t0\t1\t230433\t26.0000\tNaN\tS\n",
    "885\t886\t0\t3\tRice\tfemale\t39.0\t0\t5\t382652\t29.1250\tNaN\tQ\n",
    "129 rows × 12 columns\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "J4gx3RHIOczI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def married_surnames(df):\n",
    "    \"\"\"\"Assume married women are all Mrs in Name\"\"\"\n",
    "    df = df[df['Name'].str.contains(\"Mrs\", regex=False)]\n",
    "#     df.loc[df['Name'].str.contains(\"Mrs\", regex=False)]\n",
    "    # Get just first part of cell to get surname\n",
    "#     df['Name'].str.split(',').str.get(0)\n",
    "#     display(df)\n",
    "# df['make'] = df.id.str.split().str.get(0)\n",
    "    \n",
    "\n",
    "\n",
    "url=\"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\n",
    "dataset = pd.read_csv(url)\n",
    "# # below works outwith function\n",
    "# dataset = dataset[dataset['Name'].str.contains(\"Mrs\", regex=False)]\n",
    "# # Get just first part of cell to get surname\n",
    "# dataset['Name'] = dataset['Name'].str.split(',').str[0]\n",
    "\n",
    "married_surnames(dataset)  \n",
    "# display(column_names)\n",
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Working with Strings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
