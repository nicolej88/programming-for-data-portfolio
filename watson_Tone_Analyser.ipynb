{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-project - creating a dataframe from analysed text data\n",
    "\n",
    "For this project you are going to use the IBM Watson Tone Analyser API.  You will send text data to it, use security information stored in a config file to keep it secret, receive the results in JSON format, investigate the structure of the results and build a dataframe from them.\n",
    "\n",
    "Then you will use the results to create a visualisation of tone and to report an overall set of statistics from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1 - sign up for IBM Watson services to use the Tone Analyser\n",
    "\n",
    "1.  Sign up for IBM Watson: https://www.ibm.com/cloud/watson-studio  \n",
    "2.  Click 'Try on Cloud at no cost'  \n",
    "3.  Select the London region  (costs reduced and performance improved when you use the nearest servers)  \n",
    "4.  Create an IBM Cloud account (enter email and accept terms)  \n",
    "5.  Follow the instructions to create the account  \n",
    "6.  Provision the services  \n",
    "7.  Then go to IBM Watson Studio  \n",
    "8.  Select Tone Analyzer under the Your Services heading  \n",
    "9.  You will be shown the **url** for the Tone Analyser API and an **API key** which is needed for using the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test to make sure it works\n",
    "\n",
    "1.  Download this file, which has some text for you to test with: https://drive.google.com/file/d/1m65cPQGYQd1mwvEmfZw69-GMUBdo43k0/view?usp=sharing, put the file in the same folder as this worksheet for now.\n",
    "\n",
    "2.  Create a second text file in the same folder as this worksheet that will hold the credentials for your IBM connection to the Tone Analyser.  Add the following text to this file and save it as 'config.txt'\n",
    "\n",
    "{\"config\":{\"url\": \"...the url you got from the IBM Tone Analyser...\", \"apikey\":\"... the API key from the analyser ...\"}}  \n",
    "\n",
    "These credentials will never appear in your code as will only be readable on your device.\n",
    "\n",
    "3.  Run the code below,which will create a ToneAnalyzer with the credentials from your **config.txt** file, then feed the text from the **text-for-analysis.txt** file\n",
    "\n",
    "4.  Decide what the data looks like and how this might be represented in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm-watson in c:\\programdata\\anaconda3\\lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ibm-watson) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from ibm-watson) (2.8.1)\n",
      "Requirement already satisfied: websocket-client==1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ibm-watson) (1.1.0)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core==3.*,>=3.3.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from ibm-watson) (3.10.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm-watson) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->ibm-watson) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->ibm-watson) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->ibm-watson) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->ibm-watson) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->ibm-watson) (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade ibm-watson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document_tone': {'tones': [{'score': 0.6165, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.829888, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, 'sentences_tone': [{'sentence_id': 0, 'text': 'Team, I know that times are tough!', 'tones': [{'score': 0.801827, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 1, 'text': 'Product sales have been disappointing for the past three quarters.', 'tones': [{'score': 0.771241, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.687768, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 2, 'text': \"We have a competitive product, but we need to do a better job of selling it!'\", 'tones': [{'score': 0.506763, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}]}\n"
     ]
    }
   ],
   "source": [
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import os\n",
    "import json\n",
    "\n",
    "# get credentials from the file config.txt\n",
    "def get_secret(key):\n",
    "    # add code here to open the config.txt file and return the value associated with the iey (either 'apikey' or 'url')\n",
    "    config_file = open(\"config.txt\", \"r\")\n",
    "    config = json.loads(config_file.readline())\n",
    "    config_file.close()\n",
    "    return config['config'][key]\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "def get_text_for_analysis():\n",
    "    # add code here to open the text-for-analysis.txt file and return the text it reads as one string\n",
    "    # if there is an error, return None\n",
    "    text_file = open(\"text-for-analysis.txt\")\n",
    "    text_data = \"\"\n",
    "    for line in text_file:\n",
    "        text_data += line + \" \"\n",
    "    return text_data\n",
    "\n",
    "     \n",
    "    \n",
    "# create a ToneAnalyzerV3 object, version 2017-09-21 using api key and url from config\n",
    "authenticator = IAMAuthenticator(apikey=get_secret('api_key'))\n",
    "tone_analyzer = ToneAnalyzerV3(\n",
    "    version='2017-09-21',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "tone_analyzer.set_service_url(get_secret('url'))\n",
    "\n",
    "# get the text for analysis from the file\n",
    "text = get_text_for_analysis()\n",
    "if text:\n",
    "    tone_analysis = tone_analyzer.tone(\n",
    "        {'text': text},\n",
    "        content_type='application/json'\n",
    "    ).get_result()    \n",
    "    print(tone_analysis)\n",
    "else:\n",
    "    print(\"No data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create (on paper) an idea of how this data might be organised into a data table\n",
    "\n",
    "1.  How many bits of information are there about the document as a whole?\n",
    "2.  How many bits of information are there about each sentence?\n",
    "3.  If all tone analysis records were included in the dataframe, how many rows would there be?\n",
    "4.  What information would be included in each row?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe and start to populate with the data\n",
    "\n",
    "Before you can create a dataframe from this data you will need to convert it into a table.  One way to do this would be to create a list of dictionary records, with each record formed from the data from each row in the original 'sentences_tone' data.  You will need to loop through the rows in the 'sentences_tone' list, nesting a loop through the 'tones' list for each sentence.  For each, copy across the columns you feel should be included.\n",
    "\n",
    "_Hint:_  \n",
    "` for row in sentence_data:\n",
    "        for col in row['tones']:\n",
    "            new_row = {'sentence_id':row['sentence_id'], 'text':row['text'], 'tone_score':col['score'], 'tone_id':col['tone_id'],'tone_name':col['tone_name']}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tone_id</th>\n",
       "      <th>tone_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Team, I know that times are tough!</td>\n",
       "      <td>0.801827</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Product sales have been disappointing for the ...</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Product sales have been disappointing for the ...</td>\n",
       "      <td>0.687768</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>We have a competitive product, but we need to ...</td>\n",
       "      <td>0.506763</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                               text     score  \\\n",
       "0            0                 Team, I know that times are tough!  0.801827   \n",
       "1            1  Product sales have been disappointing for the ...  0.771241   \n",
       "2            1  Product sales have been disappointing for the ...  0.687768   \n",
       "3            2  We have a competitive product, but we need to ...  0.506763   \n",
       "\n",
       "      tone_id   tone_name  \n",
       "0  analytical  Analytical  \n",
       "1     sadness     Sadness  \n",
       "2  analytical  Analytical  \n",
       "3  analytical  Analytical  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# convert json data to table format with one row for each tone for each sentence\n",
    "def convert_to_tones(json_data):\n",
    "    # add code here to convert the json_data from the text file into a table form\n",
    "    # return the data normalized into a dataframe (pd.json_normalise(json_table))\n",
    "    datatable = []\n",
    "    for sentences in json_data[\"sentences_tone\"]:\n",
    "        for tones in sentences[\"tones\"]:\n",
    "            row = {\"sentence_id\":sentences[\"sentence_id\"],\"text\": sentences[\"text\"],'score': tones['score'],'tone_id': tones['tone_id'],'tone_name': tones['tone_name']}\n",
    "            datatable.append(row)   \n",
    "    return pd.json_normalize(datatable)       \n",
    "                \n",
    "\n",
    "tone_data = convert_to_tones(tone_analysis)\n",
    "tone_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarise the sentence data\n",
    "*  Which sentence is the most analytical?\n",
    "*  which sentence is the least analytical?\n",
    "*  what is the average analytical tone score for the sentences?\n",
    "*  what do the analytical scores look like in a bar chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tone_id</th>\n",
       "      <th>tone_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Team, I know that times are tough!</td>\n",
       "      <td>0.801827</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Product sales have been disappointing for the ...</td>\n",
       "      <td>0.687768</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>We have a competitive product, but we need to ...</td>\n",
       "      <td>0.506763</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                               text     score  \\\n",
       "0            0                 Team, I know that times are tough!  0.801827   \n",
       "2            1  Product sales have been disappointing for the ...  0.687768   \n",
       "3            2  We have a competitive product, but we need to ...  0.506763   \n",
       "\n",
       "      tone_id   tone_name  \n",
       "0  analytical  Analytical  \n",
       "2  analytical  Analytical  \n",
       "3  analytical  Analytical  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most analytical sentence is  0.801827\n",
      "The least analytical sentence is  0.506763\n",
      "The average analytical tone score is 0.6654526666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentence_id', ylabel='score'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "tone_data_sorted = tone_data[tone_data['tone_id'].str.contains('analytical')]\n",
    "display (tone_data_sorted)\n",
    "\n",
    "#most analytical sentence\n",
    "maximum = tone_data_sorted['score'].max()\n",
    "print ('The most analytical sentence is ', maximum)\n",
    "\n",
    "#least analytical sentence\n",
    "minimum = tone_data_sorted['score'].min()\n",
    "print ('The least analytical sentence is ', minimum)\n",
    "\n",
    "#average analytical tone score\n",
    "average_score = tone_data_sorted['score'].mean()\n",
    "print ('The average analytical tone score is', average_score )\n",
    "\n",
    "#seaborn barchart showing tone scores for each sentence_id.\n",
    "x = tone_data_sorted[\"sentence_id\"]\n",
    "y = tone_data_sorted[\"score\"]\n",
    "\n",
    "sns.barplot(x = x, y = y, data = tone_data_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the tone data for the whole document\n",
    "---\n",
    "\n",
    "Play with the data, create a dataframe for the document_tone, tones data (pd.json_normalize(document_tone\n",
    "Display the document score for each of the tones in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tone_id</th>\n",
       "      <th>tone_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.616500</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829888</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score     tone_id   tone_name\n",
       "0  0.616500     sadness     Sadness\n",
       "1  0.829888  analytical  Analytical"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tones_table(json_data):\n",
    "    # add code here to convert the json_data from the text file into a table form\n",
    "    # return the data normalized into a dataframe (pd.json_normalise(json_table))\n",
    "    datatable = []\n",
    "    for tones in json_data[\"document_tone\"][\"tones\"]:\n",
    "            row = {\"score\":tones[\"score\"],\"tone_id\":tones[\"tone_id\"], \"tone_name\": tones['tone_name']}\n",
    "            datatable.append(row)   \n",
    "    return pd.json_normalize(datatable)       \n",
    "                \n",
    "\n",
    "tone_data = get_tones_table(tone_analysis)\n",
    "tone_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the text in the text file and analyse the new text.\n",
    "---\n",
    "\n",
    "Here is some alternative, happier text.  Replace the text in the text-for-analysis.txt file with the text below.  Then run the notebook cells again to see the results.\n",
    "\n",
    "But I feel peaceful. Your success in the ring this morning was, to a small degree, my success. Your future is assured. You will live, secure and safe, Wilbur. Nothing can harm you now. These autumn days will shorten and grow cold. The leaves will shake loose from the trees and fall. Christmas will come, and the snows of winter. You will live to enjoy the beauty of the frozen world, for you mean a great deal to Zuckerman and he will not harm you, ever. Winter will pass, the days will lengthen, the ice will melt in the pasture pond. The song sparrow will return and sing, the frogs will awake, the warm wind will blow again. All these sights and sounds and smells will be yours to enjoy, Wilbur-this lovely world, these precious days.\n",
    "\n",
    "### Find your own examples of text, replace the text in the file again, and analyse the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document_tone': {'tones': [{'score': 0.689564, 'tone_id': 'joy', 'tone_name': 'Joy'}, {'score': 0.527599, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.802229, 'tone_id': 'confident', 'tone_name': 'Confident'}]}, 'sentences_tone': [{'sentence_id': 0, 'text': 'But I feel peaceful.', 'tones': [{'score': 0.511185, 'tone_id': 'joy', 'tone_name': 'Joy'}, {'score': 0.88939, 'tone_id': 'tentative', 'tone_name': 'Tentative'}]}, {'sentence_id': 1, 'text': 'Your success in the ring this morning was, to a small degree, my success.', 'tones': [{'score': 0.919911, 'tone_id': 'joy', 'tone_name': 'Joy'}]}, {'sentence_id': 2, 'text': 'Your future is assured.', 'tones': [{'score': 0.97759, 'tone_id': 'confident', 'tone_name': 'Confident'}]}, {'sentence_id': 3, 'text': 'You will live, secure and safe, Wilbur.', 'tones': [{'score': 0.92125, 'tone_id': 'confident', 'tone_name': 'Confident'}, {'score': 0.801827, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 4, 'text': 'Nothing can harm you now.', 'tones': []}, {'sentence_id': 5, 'text': 'These autumn days will shorten and grow cold.', 'tones': []}, {'sentence_id': 6, 'text': 'The leaves will shake loose from the trees and fall.', 'tones': [{'score': 0.536283, 'tone_id': 'fear', 'tone_name': 'Fear'}]}, {'sentence_id': 7, 'text': 'Christmas will come, and the snows of winter.', 'tones': [{'score': 0.612467, 'tone_id': 'joy', 'tone_name': 'Joy'}]}, {'sentence_id': 8, 'text': 'You will live to enjoy the beauty of the frozen world, for you mean a great deal to Zuckerman and he will not harm you, ever.', 'tones': [{'score': 0.930779, 'tone_id': 'joy', 'tone_name': 'Joy'}]}, {'sentence_id': 9, 'text': 'Winter will pass, the days will lengthen, the ice will melt in the pasture pond.', 'tones': [{'score': 0.667518, 'tone_id': 'sadness', 'tone_name': 'Sadness'}]}, {'sentence_id': 10, 'text': 'The song sparrow will return and sing, the frogs will awake, the warm wind will blow again.', 'tones': [{'score': 0.592807, 'tone_id': 'joy', 'tone_name': 'Joy'}]}, {'sentence_id': 11, 'text': 'All these sights and sounds and smells will be yours to enjoy, Wilbur-this lovely world, these precious days.', 'tones': [{'score': 0.794473, 'tone_id': 'joy', 'tone_name': 'Joy'}, {'score': 0.660207, 'tone_id': 'confident', 'tone_name': 'Confident'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# get credentials from the file config.txt\n",
    "def get_secret(key):\n",
    "    # add code here to open the config.txt file and return the value associated with the iey (either 'apikey' or 'url')\n",
    "    config_file = open(\"config.txt\", \"r\")\n",
    "    config = json.loads(config_file.readline())\n",
    "    config_file.close()\n",
    "    return config['config'][key]\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "def get_text_for_analysis():\n",
    "    # add code here to open the text-for-analysis.txt file and return the text it reads as one string\n",
    "    # if there is an error, return None\n",
    "    text_file = open(\"text-for-analysis-2.txt\")\n",
    "    text_data = \"\"\n",
    "    for line in text_file:\n",
    "        text_data += line + \" \"\n",
    "    return text_data\n",
    "\n",
    "     \n",
    "    \n",
    "# create a ToneAnalyzerV3 object, version 2017-09-21 using api key and url from config\n",
    "authenticator = IAMAuthenticator(apikey=get_secret('api_key'))\n",
    "tone_analyzer = ToneAnalyzerV3(\n",
    "    version='2017-09-21',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "tone_analyzer.set_service_url(get_secret('url'))\n",
    "\n",
    "# get the text for analysis from the file\n",
    "text = get_text_for_analysis()\n",
    "if text:\n",
    "    tone_analysis = tone_analyzer.tone(\n",
    "        {'text': text},\n",
    "        content_type='application/json'\n",
    "    ).get_result()    \n",
    "    print(tone_analysis)\n",
    "else:\n",
    "    print(\"No data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>tone_id</th>\n",
       "      <th>tone_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>But I feel peaceful.</td>\n",
       "      <td>0.511185</td>\n",
       "      <td>joy</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>But I feel peaceful.</td>\n",
       "      <td>0.889390</td>\n",
       "      <td>tentative</td>\n",
       "      <td>Tentative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Your success in the ring this morning was, to ...</td>\n",
       "      <td>0.919911</td>\n",
       "      <td>joy</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Your future is assured.</td>\n",
       "      <td>0.977590</td>\n",
       "      <td>confident</td>\n",
       "      <td>Confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>You will live, secure and safe, Wilbur.</td>\n",
       "      <td>0.921250</td>\n",
       "      <td>confident</td>\n",
       "      <td>Confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>You will live, secure and safe, Wilbur.</td>\n",
       "      <td>0.801827</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The leaves will shake loose from the trees and...</td>\n",
       "      <td>0.536283</td>\n",
       "      <td>fear</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Christmas will come, and the snows of winter.</td>\n",
       "      <td>0.612467</td>\n",
       "      <td>joy</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>You will live to enjoy the beauty of the froze...</td>\n",
       "      <td>0.930779</td>\n",
       "      <td>joy</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Winter will pass, the days will lengthen, the ...</td>\n",
       "      <td>0.667518</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>The song sparrow will return and sing, the fro...</td>\n",
       "      <td>0.592807</td>\n",
       "      <td>joy</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>All these sights and sounds and smells will be...</td>\n",
       "      <td>0.794473</td>\n",
       "      <td>joy</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>All these sights and sounds and smells will be...</td>\n",
       "      <td>0.660207</td>\n",
       "      <td>confident</td>\n",
       "      <td>Confident</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id                                               text     score  \\\n",
       "0             0                               But I feel peaceful.  0.511185   \n",
       "1             0                               But I feel peaceful.  0.889390   \n",
       "2             1  Your success in the ring this morning was, to ...  0.919911   \n",
       "3             2                            Your future is assured.  0.977590   \n",
       "4             3            You will live, secure and safe, Wilbur.  0.921250   \n",
       "5             3            You will live, secure and safe, Wilbur.  0.801827   \n",
       "6             6  The leaves will shake loose from the trees and...  0.536283   \n",
       "7             7      Christmas will come, and the snows of winter.  0.612467   \n",
       "8             8  You will live to enjoy the beauty of the froze...  0.930779   \n",
       "9             9  Winter will pass, the days will lengthen, the ...  0.667518   \n",
       "10           10  The song sparrow will return and sing, the fro...  0.592807   \n",
       "11           11  All these sights and sounds and smells will be...  0.794473   \n",
       "12           11  All these sights and sounds and smells will be...  0.660207   \n",
       "\n",
       "       tone_id   tone_name  \n",
       "0          joy         Joy  \n",
       "1    tentative   Tentative  \n",
       "2          joy         Joy  \n",
       "3    confident   Confident  \n",
       "4    confident   Confident  \n",
       "5   analytical  Analytical  \n",
       "6         fear        Fear  \n",
       "7          joy         Joy  \n",
       "8          joy         Joy  \n",
       "9      sadness     Sadness  \n",
       "10         joy         Joy  \n",
       "11         joy         Joy  \n",
       "12   confident   Confident  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_tones_table(json_data):\n",
    "    # add code here to convert the json_data from the text file into a table form\n",
    "    # return the data normalized into a dataframe (pd.json_normalise(json_table))\n",
    "    datatable = []\n",
    "    for sentences in json_data[\"sentences_tone\"]:\n",
    "        for tones in sentences[\"tones\"]:\n",
    "            row = {\"sentence_id\":sentences[\"sentence_id\"],\"text\": sentences[\"text\"],'score': tones['score'],'tone_id': tones['tone_id'],'tone_name': tones['tone_name']}\n",
    "            datatable.append(row)   \n",
    "    return pd.json_normalize(datatable)       \n",
    "                \n",
    "\n",
    "tone_data = convert_to_tones_table(tone_analysis)\n",
    "tone_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
